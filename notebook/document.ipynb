{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d28713f3",
   "metadata": {},
   "source": [
    "Data Ingestion Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1899778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'file.txt', 'pages': 1, 'author': 'Akshita Khandelwal'}, page_content='This is the main content of creating a RAG application')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "doc = Document(\n",
    "    page_content = \"This is the main content of creating a RAG application\",\n",
    "    metadata = {\n",
    "        \"source\": \"file.txt\",\n",
    "        \"pages\": 1,\n",
    "        \"author\": \"Akshita Khandelwal\"\n",
    "    }\n",
    ")\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1323f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '../data/text_files/python.txt'}, page_content=\"Python Programming\\n\\nPython is a computer programming language often used to build websites and software, automate tasks, and analyse data. \\nPython is a general-purpose language, not specialised for any specific problems, and used to create various programmes.\\nPython's syntax is a lot closer to English and so it is easier to read and write, making it the simplest type of code to learn how to write and develop with.\")]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File Loader\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"../data/text_files/python.txt\", encoding='utf-8')\n",
    "loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a1d9ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '../data/text_files/python.txt'}, page_content=\"Python Programming Intro\\n\\nPython is a computer programming language often used to build websites and software, automate tasks, and analyse data. \\nPython is a general-purpose language, not specialised for any specific problems, and used to create various programmes.\\nPython's syntax is a lot closer to English and so it is easier to read and write, making it the simplest type of code to learn how to write and develop with.\"),\n",
       " Document(metadata={'source': '../data/text_files/ml.txt'}, page_content='Machine Learning Intro\\n\\nMachine learning (ML) is a subset of artificial intelligence (AI) and computer science that focuses on using data and algorithms to enable AI systems to learn, improve, and make predictions without being explicitly programmed. \\nIt involves training models to identify patterns in data to perform tasks like classification, regression, or generation. \\n\\nKey Aspects of Machine Learning:\\n\\nTypes of ML: The four most common types are supervised learning (using labeled data), unsupervised learning (finding patterns in unlabeled data), semi-supervised learning, and reinforcement learning (trial-and-error).\\n\\nHow it Works: ML algorithms analyze large amounts of data to create a model, which then makes decisions or predictions.\\n\\nCommon Applications: Used for object detection, anomaly detection, recommendation systems (e.g., Netflix, Amazon), natural language processing, and chatbots.\\n\\nAlgorithms: Popular techniques include neural networks, decision trees, and random forests. ')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Directory Loader\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "dir_loader = DirectoryLoader(\n",
    "    \"../data/text_files\",\n",
    "    glob = \"**/*.txt\",\n",
    "    loader_cls= TextLoader,\n",
    "    loader_kwargs= {'encoding': 'utf-8'},\n",
    "    show_progress=False\n",
    ")\n",
    "\n",
    "dir_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25a35969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-10-30T10:53:00+00:00', 'source': '../data/pdf_files/Meena Jain PythonDjango  (4).pdf', 'file_path': '../data/pdf_files/Meena Jain PythonDjango  (4).pdf', 'total_pages': 2, 'format': 'PDF 1.4', 'title': 'Meena Jain Python/Django', 'author': 'Renu Fulmali', 'subject': '', 'keywords': 'DAGouASs830,BAFs0rJREMo,0', 'moddate': '2025-10-30T10:52:58+00:00', 'trapped': '', 'modDate': \"D:20251030105258+00'00'\", 'creationDate': \"D:20251030105300+00'00'\", 'page': 0}, page_content='SUMMARY\\nI’m a skilled Python/Django developer with over 5+ years of professional experience in back-end web\\ndevelopment. My core strength lies in building efficient, secure, and scalable web applications using Django\\nand related technologies. I have hands-on experience with Flask, JavaScript, PostgreSQL, MySQL, SQLite,\\nDocker, and Git, TDD and I follow Agile methodologies and best practices in API development using RESTful\\nservices. In addition to developing RESTful APIs, I have experience customizing and writing Django modules\\nto extend application functionality. I actively participate in code reviews to ensure code quality,\\nmaintainability, and adherence to coding standards. Good experience with AWS (Lambda, API Gateway, Step\\nFunctions, Cognito, S3, Aurora, DynamoDB) , AWS Lambda with Python\\nMEENA JAIN\\nEmail - meenadevj52@gmail.com\\nPYTHON / DJANGO DEVELOPER \\n     TECHNICAL SKILLS\\nBackend Frameworks: Django, Django REST\\nFramework, Flask\\nProgramming Languages: Python, JavaScript\\nFrontend Technologies: HTML, CSS, JavaScript,\\nReact, Bootstrap\\nDatabases: PostgreSQL, MySQL, MongoDB,\\nMemcached, Redis\\nAWS S3, SNS, SQS\\nTools & Platforms: Amazon Web Services (AWS),\\nAWS Lambda , GitHub, CI/ CD ,  TDD, REST, JSON \\nOther Skills: RESTful API Development, Full Stack\\nDevelopment, Frontend & Backend Development,\\nCelery, Load Balancing, Requirements Gathering,\\nUser Interface (UI) Design\\nEventbridge/Step-functions/App Flow\\nException Handling in AWS & Monitoring\\nECS, EKS, Devops\\nCompleted BCOM -  in Computer\\nDevi Ahilya Vishwavidyalaya  - Completed in 2015\\n     EDUCATION\\nJan 2021 to Present\\nBack-end developer||Python/Django\\nWork as Remote Contract developer   \\nPrecious Infosystem Pvt. Ltd.|\\n    Responsibilities:\\nTight communication with a distributed project team of frontend & backend developers as well as\\nproduct owner to prioritize and allocate tasks.\\nPython/Django backend design & development.\\nDjango REST Framework REST API design & development.\\nUsed AWS Lambda with Django for serverless processing and seamless integration with services\\nlike S3 and RDS.\\nAPI design in collaboration with a Frontend Developer.\\nBackend & REST API testing via pytest & its ecosystem.\\nWork as part of a modern agile development team \\nCollaborated with frontend developers to design APIs that are easy to use.\\nIntegrated third-party services and APIs as needed.\\nCode review, Performance optimization.\\nHandled bug fixes and optimized backend performance.\\nManaged version control using Git and handled deployments.\\n     PROFESSIONAL EXPERIENCE'),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-10-30T10:53:00+00:00', 'source': '../data/pdf_files/Meena Jain PythonDjango  (4).pdf', 'file_path': '../data/pdf_files/Meena Jain PythonDjango  (4).pdf', 'total_pages': 2, 'format': 'PDF 1.4', 'title': 'Meena Jain Python/Django', 'author': 'Renu Fulmali', 'subject': '', 'keywords': 'DAGouASs830,BAFs0rJREMo,0', 'moddate': '2025-10-30T10:52:58+00:00', 'trapped': '', 'modDate': \"D:20251030105258+00'00'\", 'creationDate': \"D:20251030105300+00'00'\", 'page': 1}, page_content='Hellomaas: https://hellomaas.com/en/\\nSkills - Python, Django, DRF, React, AWS, TDD\\nDescription - Its a marketing Platform for the client and freelancer, for the payment flow they\\nused stripe, I worked on many modules.\\nRoles and responsibilities:\\nWorked as a Full stack developer and complete the task within deadline.\\nPython/Django backend design & development.\\nDjango REST Framework REST API design & development.\\nAPI design in collaboration with a Frontend Developer.\\nWork as part of a modern agile development team\\nImprove functionality of existing systems\\nTPE -Hub: https://www.tpehub.com/\\nSkills - Python, Django, Testcases ,Frontend UI , React.js / Redux , Heroku , TDD\\nDescription -Building financial tools and dashboards to help customers get a better track on\\ntheir finances\\nRole responsibility:\\nWorked on both backend Django and FRontend - React.js, write testcases, implement\\nfeature etc\\nPython/Django backend design & development.\\nDjango REST Framework REST API design & development.\\nHandled bug fixes and optimized backend performance.\\nThe Bookie: https://www.thebookie.nl/\\nSkills - Python, Django, Testcases, TDD\\nDescription - The Bookie is not one accountant, your bookies form a team. Good for you,\\nbecause that means we are always there for you and you will be helped quickly.\\nRole responsibility \\nDeveloped and maintained web applications using Django.\\nBuilt and integrated RESTful APIs with Django REST Framework.\\nWrote test cases to ensure code quality and reliability.\\nCollaborated with team members to implement new features.\\nABOUT MY PROJECTS :\\nJan 2020 to Dec 2021\\nDjango developer||\\nPrecious Infosystem Pvt. Ltd.|\\nSkills: Python, Django, JavaScript, jQuery, AJAX, Git, Heroku, Capistrano, Linux, AWS, Lambda more.\\nResponsibilities: Involved in end-to-end development including requirement gathering, system\\nanalysis, design, coding, testing, and deployment.\\nCoordinate with internal teams to understand user requirements and provide technical solutions \\nBack-end developer|| Django\\nStrivepool Webtech Pvt. Ltd.|\\nJuly 2019-Dec 2020\\nDesigned, developed, and maintained Python-based web applications.\\nBuilt and integrated RESTful APIs using Django and Django REST Framework.\\nDeveloped dynamic websites using Django and JavaScript.\\nImplemented REST API calls and handled JSON data for seamless data exchange.\\nParticipated in client meetings and requirement-gathering sessions to understand project needs and\\ndeliver technical solutions.'),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-04-08T08:54:54+00:00', 'source': '../data/pdf_files/Munmun T Updated Python Resume (3).pdf', 'file_path': '../data/pdf_files/Munmun T Updated Python Resume (3).pdf', 'total_pages': 2, 'format': 'PDF 1.4', 'title': 'White Minimalist Web Designer Resume', 'author': 'Munmun Tomar', 'subject': '', 'keywords': 'DAGj8rXpRgA,BADhy8Lb60c,0', 'moddate': '2025-04-08T08:54:53+00:00', 'trapped': '', 'modDate': \"D:20250408085453+00'00'\", 'creationDate': \"D:20250408085454+00'00'\", 'page': 0}, page_content='Munmun Tomar\\nPython Developer\\nI ’m a Python Django Developer with 6+ years of experience in building scalable web applications. Skilled in\\nDjango, DRF, and RESTful APIs, with expertise in database management and cloud deployment.\\nExperienced in frontend integration, version control, and performance optimization. I focus on writing\\nsecure and maintainable code while keeping up with new technologies. Proficient in Python, Django, Fast\\nAPI and front-end technologies, with a strong understanding of RESTful APIs, database management, and\\nversion control systems. Experienced in optimizing performance, debugging, and delivering scalable,\\nsecure solutions.\\ntmunmun090@gmail.com\\nPRECIOUS INFOSYSTEM PVT LTD || Senior Software Engineer || Remote \\nDeveloped and optimized web applications using Django, DRF and PostgreSQL. \\nBuilt RESTful and Graph QL APIs for seamless integration. \\nDesigned and implemented RESTful APIs using Django REST Framework and Fast API. \\nIntegrated third-party APIs and payment gateways for seamless transactions.\\nCollaborated with frontend developers to enhance UX and UI functionality.\\nDeployed and managed applications on AWS with CI/CD pipelines. \\nManaged version control using GitHub and Bitbucket ensuring smooth collaboration and code\\nintegrity. \\nImplemented authentication and authorization systems using JWT/OAuth.\\nMar  2019 to Presnt\\nExperience\\nBachelor Degree\\nProgramming Languages: Python (Expert), JavaScript (Intermediate), HTML5 (Intermediate),\\nCSS3 (Intermediate), SQL (Expert) \\nFrameworks/Libraries: Django (Expert), Fast API (Intermediate), React (Basic), Bootstrap (Basic),\\njQuery (Basic)\\nDatabases & ORMs: PostgreSQL (Advanced), MySQL (Intermediate), MongoDB (Intermediate),\\nSQLAlchemy (Intermediate), Django ORM (Advanced) \\nTools & Platforms: Git (Expert), Docker (Intermediate), \\nCloud Services: AWS (Basic), Heroku (Basic), Linux (Intermediate)\\nProblem-solving\\nCreativity\\nTime Management and Eye for Detail\\nRGPV University \\nBachelor of Computer Science and Technology - Graduated in 2018\\nEducation\\nSkills\\nSummary'),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-04-08T08:54:54+00:00', 'source': '../data/pdf_files/Munmun T Updated Python Resume (3).pdf', 'file_path': '../data/pdf_files/Munmun T Updated Python Resume (3).pdf', 'total_pages': 2, 'format': 'PDF 1.4', 'title': 'White Minimalist Web Designer Resume', 'author': 'Munmun Tomar', 'subject': '', 'keywords': 'DAGj8rXpRgA,BADhy8Lb60c,0', 'moddate': '2025-04-08T08:54:53+00:00', 'trapped': '', 'modDate': \"D:20250408085453+00'00'\", 'creationDate': \"D:20250408085454+00'00'\", 'page': 1}, page_content='Cloud-based analytics and Reporting system\\nIt is a  centralized platform designed to ingest, process, store, and visualize data from multiple sources\\n(e.g., transactional systems, APIs, 3rd party tools), hosted in a cloud environment AWS. Users interact with\\ndashboards, reports, or embedded analytics to make data-driven decisions.\\nSkills: Django, Jasper Tool, PostgreSQL, MySql, ELK, Docker, Celery\\nRoles and Responsibilities: \\nDeveloped a comprehensive Cloud-based Analytics and Reporting System that allows users to create\\n        dynamic reports using JasperTool.\\nThe entire system is containerized using Docker for seamless deployment and scalability. \\nUsed Celery and Redis for asynchronous tasks Explore and integrate emerging technologies such as\\nconsensus protocols to enhance project functionality. \\nContribute to all phases of the software development lifecycle, including requirement analysis, design,\\ncoding, testing, and deployment. \\nAdapt to project needs and ensure timely delivery of high-quality software solutions.\\nMailHub\\nSkills: Django, Python, MYSQL, Amazon SES, Amazon SNS, Amazon EC2, Docker, Git\\nA centralized communication platform or service to manage email notifications, messaging queues,\\ntemplates, or user communications, built using Python, Django, and possibly other services like Redis,\\nCelery, or third-party email APIs \\nResponsibilities:\\nDesigned and developed RESTful APIs to send, track, and manage emails.\\nBuilt and maintained Django models, serializers, and views for email templates, user preferences, and\\ndelivery logs.\\nImplemented logic for email scheduling, retries, and status tracking.\\nDesigned normalized schemas using PostgreSQL or MySQL for storing email metadata, user configs,\\nand send history.\\nWrote optimized Django ORM queries and raw SQL for performance-critical endpoints.\\nAutoSync Wizard\\nSkills: Django, Python, MYSQL, LDAP, Swagger, Git\\nThe AutoSync Wizard is a sophisticated project with three interconnected components: Cloud, On-\\nPremise, and Client. The Cloud serves as the centralized hub, allowing users to select versions, while On-\\nPremise fetches the selected version from the Cloud and provides it to the Client at scheduled intervals.\\nWebSocket communication, powered by the Tornado framework, facilitates real-time connectivity\\nbetween the Cloud and On-Premise components. Swagger enhances API visualization, and Docker\\nefficiently manages containers for Celery and Django.\\nResponsibilities: \\nDeveloped Django models, views, and APIs to manage sync configurations, schedules, and job logs.\\nCreated RESTful endpoints for triggering and monitoring sync jobs.\\nImplemented reusable utilities for handling data mapping, transformation, and conflict resolution.\\nDesigned and implemented core logic for detecting data changes (delta sync, full sync).\\nBuilt connectors for syncing data with REST APIs, FTP, local files, and databases.\\nEnsured idempotency, error handling, and retries in sync operations.\\nI would be grateful for the opportunity to discuss my qualifications with you in more detail. Thanks!\\nProject Details')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Directory Loader for PDF\n",
    "from langchain_community.document_loaders import DirectoryLoader, PyMuPDFLoader\n",
    "\n",
    "dir_loader_pdf = DirectoryLoader(\n",
    "    \"../data/pdf_files\",\n",
    "    glob = \"**/*.pdf\",\n",
    "    loader_cls= PyMuPDFLoader,\n",
    "    show_progress=False\n",
    ")\n",
    "\n",
    "dir_loader_pdf.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a98813c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '../data/google_sheets/Untitled spreadsheet - Sheet4.csv', 'row': 0}, page_content='Q1. Get all books priced less than 500: Q2. Get all books priced less than or equal to 500\\nBook.objects.filter(price__lt=500): Book.objects.filter(price__lte=500)'),\n",
       " Document(metadata={'source': '../data/google_sheets/Untitled spreadsheet - Sheet4.csv', 'row': 1}, page_content='Q1. Get all books priced less than 500: Q3. Get all books priced greater than 1000\\nBook.objects.filter(price__lt=500): Book.objects.filter(price__gt=1000)'),\n",
       " Document(metadata={'source': '../data/google_sheets/Untitled spreadsheet - Sheet4.csv', 'row': 2}, page_content='Q1. Get all books priced less than 500: Q4. Get all books with rating greater than or equal to 4.5\\nBook.objects.filter(price__lt=500): Book.objects.filter(rating__gte=4.5)'),\n",
       " Document(metadata={'source': '../data/google_sheets/Untitled spreadsheet - Sheet4.csv', 'row': 3}, page_content='Q1. Get all books priced less than 500: Q5. Get books with title exactly \"Django Basics\"\\nBook.objects.filter(price__lt=500): Book.objects.filter(title__exact=\"Django Basics\")'),\n",
       " Document(metadata={'source': '../data/google_sheets/Untitled spreadsheet - Sheet4.csv', 'row': 4}, page_content='Q1. Get all books priced less than 500: Q6. Get books with title \"django basics\" (case-insensitive)\\nBook.objects.filter(price__lt=500): Book.objects.filter(title__iexact=\"django basics\")'),\n",
       " Document(metadata={'source': '../data/google_sheets/Untitled spreadsheet - Sheet4.csv', 'row': 5}, page_content='Q1. Get all books priced less than 500: Q7. Get books whose title contains \"django\"\\nBook.objects.filter(price__lt=500): Book.objects.filter(title__contains=\"django)'),\n",
       " Document(metadata={'source': '../data/google_sheets/Untitled spreadsheet - Sheet4.csv', 'row': 6}, page_content='Q1. Get all books priced less than 500: Q8. Get all books written by an author named \"Rahul\"\\nBook.objects.filter(price__lt=500): Book.objects.filter(author__name=\"Rahul\")'),\n",
       " Document(metadata={'source': '../data/google_sheets/Untitled spreadsheet - Sheet4.csv', 'row': 7}, page_content='Q1. Get all books priced less than 500: Q9. Get books written by authors older than 40\\nBook.objects.filter(price__lt=500): Book.objects.filter(author__age__gt=40)'),\n",
       " Document(metadata={'source': '../data/google_sheets/Untitled spreadsheet - Sheet4.csv', 'row': 8}, page_content='Q1. Get all books priced less than 500: Q10. Get books published by publishers from \"India\"\\nBook.objects.filter(price__lt=500): Book.objects.filter(publisher__country__iexact=\"india\")'),\n",
       " Document(metadata={'source': '../data/google_sheets/Untitled spreadsheet - Sheet4.csv', 'row': 9}, page_content='Q1. Get all books priced less than 500: Q11. Get all books of a specific author (author id = 1)\\nBook.objects.filter(price__lt=500): # Book.objects.filter(author__id=1)\\nauthor = Author.objects.get(id=1)\\nauthor.books.all()'),\n",
       " Document(metadata={'source': '../data/google_sheets/Untitled spreadsheet - Sheet4.csv', 'row': 10}, page_content='Q1. Get all books priced less than 500: Q12. Get authors who have written at least one book\\nBook.objects.filter(price__lt=500): # Author.objects.filter(books__isNull=False)\\nAuthor.objects.filter(books__isnull=False).distinct()'),\n",
       " Document(metadata={'source': '../data/google_sheets/Untitled spreadsheet - Sheet4.csv', 'row': 11}, page_content=\"Q1. Get all books priced less than 500: Q13. Get only titles and prices of all books\\nBook.objects.filter(price__lt=500): # Book.objects.filter(values_list=['title', 'price'])\\nBook.objects.values('title', 'price')\"),\n",
       " Document(metadata={'source': '../data/google_sheets/Untitled spreadsheet - Sheet4.csv', 'row': 12}, page_content=\"Q1. Get all books priced less than 500: Q14. Get a list of all book titles\\nBook.objects.filter(price__lt=500): Book.objects.values_list('title')\"),\n",
       " Document(metadata={'source': '../data/google_sheets/Untitled spreadsheet - Sheet4.csv', 'row': 13}, page_content=\"Q1. Get all books priced less than 500: Q15. Get author names with book titles\\nBook.objects.filter(price__lt=500): Book.objects.values('author__name', 'title')\"),\n",
       " Document(metadata={'source': '../data/google_sheets/Untitled spreadsheet - Sheet4.csv', 'row': 14}, page_content=\"Q1. Get all books priced less than 500: Q16. Count number of books written by each author\\nBook.objects.filter(price__lt=500): # Book.objects.filter(author__name).values('title)\\nAuthor.objects.annotate(book_count=Count('books'))\"),\n",
       " Document(metadata={'source': '../data/google_sheets/Untitled spreadsheet - Sheet4.csv', 'row': 15}, page_content=\"Q1. Get all books priced less than 500: Q17. Get authors with more than 2 books\\nBook.objects.filter(price__lt=500): Author.objects.annotate(book_count=Count('books').filter(book_count__gt=2)\"),\n",
       " Document(metadata={'source': '../data/google_sheets/Untitled spreadsheet - Sheet4.csv', 'row': 16}, page_content=\"Q1. Get all books priced less than 500: Q18. Get average book rating per author\\nBook.objects.filter(price__lt=500): Author.objects.annotate(avg_rating=Avg('books__rating')\"),\n",
       " Document(metadata={'source': '../data/google_sheets/Untitled spreadsheet - Sheet4.csv', 'row': 17}, page_content=\"Q1. Get all books priced less than 500: Q19. Get publisher-wise maximum book price\\nBook.objects.filter(price__lt=500): Publisher.objects.annotate(max_price=Max('books__price'))\"),\n",
       " Document(metadata={'source': '../data/google_sheets/Untitled spreadsheet - Sheet4.csv', 'row': 18}, page_content=\"Q1. Get all books priced less than 500: Q26. Get authors whose average book rating > 4\\nBook.objects.filter(price__lt=500): Author.objects.annotate(avg_rating=Avg('books__rating').filter(avg_rating__gt=4)\"),\n",
       " Document(metadata={'source': '../data/google_sheets/Untitled spreadsheet - Sheet4.csv', 'row': 19}, page_content=\"Q1. Get all books priced less than 500: Q27. Get top 3 most expensive books\\nBook.objects.filter(price__lt=500): Book.objects.order_by('-price')[:3]\"),\n",
       " Document(metadata={'source': '../data/google_sheets/Untitled spreadsheet - Sheet4.csv', 'row': 20}, page_content='Q1. Get all books priced less than 500: Q28. Check if any book exists with price > 5000\\nBook.objects.filter(price__lt=500): Book.objects.filter(price__gt=5000).exists()')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Directory Loader for Excel\n",
    "from langchain_community.document_loaders import DirectoryLoader, CSVLoader\n",
    "\n",
    "dir_loader = DirectoryLoader(\n",
    "    \"../data/google_sheets\",\n",
    "    glob = \"**/*.csv\",\n",
    "    loader_cls= CSVLoader,\n",
    "    show_progress=False\n",
    ")\n",
    "\n",
    "dir_loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5787b19f",
   "metadata": {},
   "source": [
    "Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eeb59556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from typing import List, Tuple, Any, Dict\n",
    "import uuid \n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9072067",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 332.00it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded succesfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingManager at 0x7ec4b4c67fe0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EmbeddingManager:\n",
    "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "\n",
    "    def _load_model(self):\n",
    "        try:\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(\"Model loaded succesfully\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model {self.model_name}: {e}\")  \n",
    "\n",
    "    \n",
    "    def generate_embeddings(self, texts: List[str]):\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded\")\n",
    "        \n",
    "        print(\"Generating embeddings\")\n",
    "        embeddings = self.model.encode(texts, show_progress_bar=True)\n",
    "        print(\"Generated embeddings with shape:\", embeddings.shape)\n",
    "        \n",
    "        return embeddings\n",
    "    \n",
    "\n",
    "embed = EmbeddingManager()\n",
    "embed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38984b5",
   "metadata": {},
   "source": [
    "VectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dde72571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Store initialized. Collection = pdf_documents 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.VectorStore at 0x7ec4b162ad20>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "\n",
    "class VectorStore:\n",
    "    def __init__(self, collection_name: str = 'pdf_documents', persist_directory: str = '../data/vector_store'):\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self.initialize_store()\n",
    "\n",
    "    def initialize_store(self):\n",
    "        try:\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "            self.client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "\n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name=self.collection_name,\n",
    "                metadata={\"description\": \"PDF document embeddings for RAG\"}\n",
    "            )\n",
    "            print(\"Vector Store initialized. Collection =\", self.collection_name, self.collection.count())\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model {self.model_name}: {e}\")   \n",
    "\n",
    "\n",
    "    def add_documents(self, documents: List[Any], embeddings: np.ndarray):\n",
    "        if len(documents) != len(embeddings):\n",
    "            raise ValueError(\"Number of documents do not match\")\n",
    "        \n",
    "        ids = []\n",
    "        metadatas = []\n",
    "        document_text = []\n",
    "        embeddings_list = []\n",
    "\n",
    "        for i, (doc, embedding) in enumerate(zip(documents, embeddings)):\n",
    "            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata['doc_index'] = i\n",
    "            metadata['content_length'] = len(doc.page_content)\n",
    "            metadatas.append(metadata)\n",
    "\n",
    "            document_text.append(doc.page_content)\n",
    "\n",
    "            embeddings_list.append(embedding.tolist())\n",
    "\n",
    "            try:\n",
    "                self.collection.add(\n",
    "                    ids=ids,\n",
    "                    embeddings=embeddings_list,\n",
    "                    metadatas=metadatas,\n",
    "                    documents=document_text\n",
    "                )\n",
    "\n",
    "                print(f\"Succesfully added {len(documents)} documents to vector store\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading model {self.model_name}: {e}\")  \n",
    "            \n",
    "\n",
    "vector_store = VectorStore()\n",
    "vector_store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8bd493",
   "metadata": {},
   "source": [
    "Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68c623e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 4 documents into 13 chunks\n",
      "Content: SUMMARY\n",
      "I’m a skilled Python/Django developer with...\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Any\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "def split_documents(documents: List[Any], chunk_size: int = 1000, chunk_overlap: int = 200):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    print(f\"Split {len(documents)} documents into {len(split_docs)} chunks\")\n",
    "\n",
    "    if split_docs:\n",
    "        print(f\"Content: {split_docs[0].page_content[:50]}...\")\n",
    "\n",
    "    return split_docs\n",
    "\n",
    "\n",
    "all_pdfs = dir_loader_pdf.load()\n",
    "chunks = split_documents(all_pdfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01b39d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (13, 384)\n",
      "Succesfully added 13 documents to vector store\n",
      "Succesfully added 13 documents to vector store\n",
      "Succesfully added 13 documents to vector store\n",
      "Succesfully added 13 documents to vector store\n",
      "Succesfully added 13 documents to vector store\n",
      "Succesfully added 13 documents to vector store\n",
      "Succesfully added 13 documents to vector store\n",
      "Succesfully added 13 documents to vector store\n",
      "Succesfully added 13 documents to vector store\n",
      "Succesfully added 13 documents to vector store\n",
      "Succesfully added 13 documents to vector store\n",
      "Succesfully added 13 documents to vector store\n",
      "Succesfully added 13 documents to vector store\n"
     ]
    }
   ],
   "source": [
    "# Convert text to embeddings\n",
    "\n",
    "text_var = [doc.page_content for doc in chunks]\n",
    "\n",
    "embeddings = embed.generate_embeddings(text_var)\n",
    "vector_store.add_documents(chunks, embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9185250",
   "metadata": {},
   "source": [
    "Data Retrieval Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d29766bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for What is summary?\n",
      "Generating embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 93.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "0.17406773567199707\n",
      "0.1401815414428711\n",
      "0.11842691898345947\n",
      "Retrieved 3 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'doc_cfbac0a8_9',\n",
       "  'content': 'Cloud-based analytics and Reporting system\\nIt is a  centralized platform designed to ingest, process, store, and visualize data from multiple sources\\n(e.g., transactional systems, APIs, 3rd party tools), hosted in a cloud environment AWS. Users interact with\\ndashboards, reports, or embedded analytics to make data-driven decisions.\\nSkills: Django, Jasper Tool, PostgreSQL, MySql, ELK, Docker, Celery\\nRoles and Responsibilities: \\nDeveloped a comprehensive Cloud-based Analytics and Reporting System that allows users to create\\n        dynamic reports using JasperTool.\\nThe entire system is containerized using Docker for seamless deployment and scalability. \\nUsed Celery and Redis for asynchronous tasks Explore and integrate emerging technologies such as\\nconsensus protocols to enhance project functionality. \\nContribute to all phases of the software development lifecycle, including requirement analysis, design,\\ncoding, testing, and deployment.',\n",
       "  'metadata': {'page': 1,\n",
       "   'file_path': '../data/pdf_files/Munmun T Updated Python Resume (3).pdf',\n",
       "   'moddate': '2025-04-08T08:54:53+00:00',\n",
       "   'doc_index': 9,\n",
       "   'producer': 'Canva',\n",
       "   'content_length': 947,\n",
       "   'modDate': \"D:20250408085453+00'00'\",\n",
       "   'source': '../data/pdf_files/Munmun T Updated Python Resume (3).pdf',\n",
       "   'keywords': 'DAGj8rXpRgA,BADhy8Lb60c,0',\n",
       "   'trapped': '',\n",
       "   'creationDate': \"D:20250408085454+00'00'\",\n",
       "   'subject': '',\n",
       "   'creationdate': '2025-04-08T08:54:54+00:00',\n",
       "   'creator': 'Canva',\n",
       "   'author': 'Munmun Tomar',\n",
       "   'total_pages': 2,\n",
       "   'format': 'PDF 1.4',\n",
       "   'title': 'White Minimalist Web Designer Resume'},\n",
       "  'distance': 1.6518645286560059,\n",
       "  'similarity_score': 0.17406773567199707,\n",
       "  'rank': 1},\n",
       " {'id': 'doc_0ab41b92_8',\n",
       "  'content': 'jQuery (Basic)\\nDatabases & ORMs: PostgreSQL (Advanced), MySQL (Intermediate), MongoDB (Intermediate),\\nSQLAlchemy (Intermediate), Django ORM (Advanced) \\nTools & Platforms: Git (Expert), Docker (Intermediate), \\nCloud Services: AWS (Basic), Heroku (Basic), Linux (Intermediate)\\nProblem-solving\\nCreativity\\nTime Management and Eye for Detail\\nRGPV University \\nBachelor of Computer Science and Technology - Graduated in 2018\\nEducation\\nSkills\\nSummary',\n",
       "  'metadata': {'content_length': 442,\n",
       "   'modDate': \"D:20250408085453+00'00'\",\n",
       "   'total_pages': 2,\n",
       "   'format': 'PDF 1.4',\n",
       "   'creationDate': \"D:20250408085454+00'00'\",\n",
       "   'subject': '',\n",
       "   'trapped': '',\n",
       "   'keywords': 'DAGj8rXpRgA,BADhy8Lb60c,0',\n",
       "   'doc_index': 8,\n",
       "   'title': 'White Minimalist Web Designer Resume',\n",
       "   'page': 0,\n",
       "   'author': 'Munmun Tomar',\n",
       "   'source': '../data/pdf_files/Munmun T Updated Python Resume (3).pdf',\n",
       "   'moddate': '2025-04-08T08:54:53+00:00',\n",
       "   'creationdate': '2025-04-08T08:54:54+00:00',\n",
       "   'producer': 'Canva',\n",
       "   'file_path': '../data/pdf_files/Munmun T Updated Python Resume (3).pdf',\n",
       "   'creator': 'Canva'},\n",
       "  'distance': 1.7196369171142578,\n",
       "  'similarity_score': 0.1401815414428711,\n",
       "  'rank': 2},\n",
       " {'id': 'doc_94a3cf6c_10',\n",
       "  'content': 'consensus protocols to enhance project functionality. \\nContribute to all phases of the software development lifecycle, including requirement analysis, design,\\ncoding, testing, and deployment. \\nAdapt to project needs and ensure timely delivery of high-quality software solutions.\\nMailHub\\nSkills: Django, Python, MYSQL, Amazon SES, Amazon SNS, Amazon EC2, Docker, Git\\nA centralized communication platform or service to manage email notifications, messaging queues,\\ntemplates, or user communications, built using Python, Django, and possibly other services like Redis,\\nCelery, or third-party email APIs \\nResponsibilities:\\nDesigned and developed RESTful APIs to send, track, and manage emails.\\nBuilt and maintained Django models, serializers, and views for email templates, user preferences, and\\ndelivery logs.\\nImplemented logic for email scheduling, retries, and status tracking.\\nDesigned normalized schemas using PostgreSQL or MySQL for storing email metadata, user configs,\\nand send history.',\n",
       "  'metadata': {'file_path': '../data/pdf_files/Munmun T Updated Python Resume (3).pdf',\n",
       "   'creationDate': \"D:20250408085454+00'00'\",\n",
       "   'trapped': '',\n",
       "   'format': 'PDF 1.4',\n",
       "   'creationdate': '2025-04-08T08:54:54+00:00',\n",
       "   'author': 'Munmun Tomar',\n",
       "   'modDate': \"D:20250408085453+00'00'\",\n",
       "   'producer': 'Canva',\n",
       "   'subject': '',\n",
       "   'moddate': '2025-04-08T08:54:53+00:00',\n",
       "   'doc_index': 10,\n",
       "   'keywords': 'DAGj8rXpRgA,BADhy8Lb60c,0',\n",
       "   'title': 'White Minimalist Web Designer Resume',\n",
       "   'page': 1,\n",
       "   'content_length': 990,\n",
       "   'creator': 'Canva',\n",
       "   'source': '../data/pdf_files/Munmun T Updated Python Resume (3).pdf',\n",
       "   'total_pages': 2},\n",
       "  'distance': 1.763146162033081,\n",
       "  'similarity_score': 0.11842691898345947,\n",
       "  'rank': 3}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RAGRetreiver:\n",
    "    def __init__(self, embedding_manager: EmbeddingManager, vector_store: VectorStore):\n",
    "        self.vector_store = vector_store\n",
    "        self.embedding_manager = embedding_manager\n",
    "\n",
    "    def retrieve(self, query: str, top_k: int=3, score_threshold: float=0.0) -> List[Dict[str, Any]]:\n",
    "        print(\"Retrieving documents for\", query)\n",
    "\n",
    "        query_embedding = self.embedding_manager.generate_embeddings([query])[0]\n",
    "        try:\n",
    "            results = self.vector_store.collection.query(\n",
    "                query_embeddings=[query_embedding.tolist()],\n",
    "                n_results=top_k\n",
    "            )\n",
    "            # print(results['documents'][0])\n",
    "\n",
    "            retrieved_docs = []\n",
    "            if results['documents'] and results['documents'][0]:\n",
    "                documents = results['documents'][0]\n",
    "                metadatas = results['metadatas'][0]\n",
    "                distances = results['distances'][0]\n",
    "                ids = results['ids'][0]\n",
    "\n",
    "                for i, (doc_id, document, metadata, distance) in enumerate(zip(ids, documents, metadatas, distances)):\n",
    "                    similarity_score = 1 - distance / 2\n",
    "                    print(similarity_score)\n",
    "                    if similarity_score >= score_threshold:\n",
    "                        retrieved_docs.append({\n",
    "                            'id': doc_id,\n",
    "                            'content': document,\n",
    "                            'metadata': metadata,\n",
    "                            'distance': distance,\n",
    "                            'similarity_score': similarity_score,\n",
    "                            'rank': i+1\n",
    "                        })\n",
    "\n",
    "                print(f\"Retrieved {len(retrieved_docs)} documents\")\n",
    "            else:\n",
    "                print(\"No docs found\")\n",
    "\n",
    "            return retrieved_docs\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(\"Exception:\", e)\n",
    "    \n",
    "\n",
    "\n",
    "rag_retriever = RAGRetreiver(embed, vector_store)\n",
    "query = \"What is summary?\"\n",
    "rag_retriever.retrieve(query)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
